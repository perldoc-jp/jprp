
=encoding euc-jp

=head1 NAME

=begin original

DBD::SQLite - Self Contained RDBMS in a DBI Driver

=end original

DBD::SQLite - DBI ドライバでの自己完結型(Self Contained)RDBMS

=head1 SYNOPSIS

  use DBI;
  my $dbh = DBI->connect("dbi:SQLite:dbname=dbfile","","");

=head1 DESCRIPTION

=begin original

SQLite is a public domain RDBMS database engine that you can find
at http://www.hwaci.com/sw/sqlite/.

=end original

SQLite は、パブリックドメインのRDBMSデータベースエンジンです;
この URL で見つけることが出来ます: http://www.hwaci.com/sw/sqlite/.

=begin original

Rather than ask you to install SQLite first, because SQLite is public
domain, DBD::SQLite includes the entire thing in the distribution. So
in order to get a fast transaction capable RDBMS working for your
perl project you simply have to install this module, and B<nothing>
else.

=end original

SQLite を先にインストールするように頼むよりも、SQLite が
パブリックドメインであることから、DBD::SQLite は全てのものを
ディストリビューションに含んでいます。
そのためあなたの perl プロジェクトのために、高速の
トランザクション可能な RDBMS を動かすためには、単にこのモジュールを
インストールすることだけが必要です。
他には B<何もありません>。

=begin original

SQLite supports the following features:

=end or iginal

SQLiteは以下の機能をサポートしています:

=over 4

=item Implements a large subset of SQL92

(SQL92 のサブセットの多くを実装)

=begin original

See http://www.hwaci.com/sw/sqlite/lang.html for details.

=end original

詳細は http://www.hwaci.com/sw/sqlite/lang.html をご覧ください。

=item A complete DB in a single disk file

(単一のディスクファイルでの完全な DB)

=begin original

Everything for your database is stored in a single disk file, making it
easier to move things around than with DBD::CSV.

=end original

あなたのデータベースのための全ては一つのディスクファイルに格納されます。
これにより DBD::CSV よりも簡単に動かすことが出来ます。

=item Atomic commit and rollback

(アトミックなコミットとロールバック)

=begin original

Yes, DBD::SQLite is small and light, but it supports full transactions!

=end original

そうです、DBD::SQLite は小さく、軽量ですが、
完全なトランザクションをサポートします。

=back

=begin original

There's lots more to it, but this is early development stages, so please
refer to the docs on the SQLite web page, listed above, for SQL details.

=end original

これ以上のものがありますが、これままだ開発段階の初期です。
そのため SQL の詳細については、上に挙げた SQLite web ページにある
ドキュメントを参照してください。

=head1 API

=begin original

The API works exactly as every DBI module does. Please see L<DBI> for more
details.

=end original

API は厳密に各 DBI モジュールがするように機能します。
更なる詳細については L<DBI> をご覧ください。

=head2 $dbh->func('last_insert_rowid')

=begin original

This method returns the last inserted rowid. If you specify an INTEGER PRIMARY
KEY as the first column in your table, that is the column that is returned.
Otherwise, it is the hidden ROWID column. See the sqlite docs for details.

=end original

このメソッドは最後に挿入された rowid を返します。
もし INTEGER PRIMARY KEY をあなたのテーブルでの先頭カラムとして指定すれば、
返されるのはそのカラムになります。
そうでなければ、それは隠された ROWID カラムになります。
詳細については sqlite ドキュメントをご覧ください。

=head1 NOTES

=begin original

To access the database from the command line, try using dbish which comes with
the DBI module. Just type:

=end original

コマンドラインからデータベースにアクセスするためには、DBI モジュールに
入っている dbish を試してみてください。
以下のようにタイプして:

  dbish dbi:SQLite:foo.db

=begin original

On the command line to access the file F<foo.db>.

=end original

コマンドラインでファイル F<foo.db> にアクセスします。

=begin original

Alternatively you can install SQLite from the link above without conflicting
with DBD::SQLite and use the supplied C<sqlite> command line tool.

=end original

代わりとして、上記のリンクから DBD::SQLite にぶつかることなく SQLite を
インストールし、提供される C<sqlite> コマンドラインツールを使うことが
出来ます。

=head1 PERFORMANCE

(性能)

=begin original

SQLite is fast, very fast. I recently processed my 72MB log file with it,
inserting the data (400,000+ rows) by using transactions and only committing
every 1000 rows (otherwise the insertion is quite slow), and then performing
queries on the data.

=end original

SQLiteは 高速です、非常に高速です。
私は最近、私の 72MB のログファイルをそれで処理しました。
単純に 1000 行毎にコミットしながら(そうでなければ挿入がとても遅くなります)、
トランザクションを使ってデータ(400,000 以上の行)を挿入し、
そのデータに問い合わせを実行しました。

=begin original

Queries like count(*) and avg(bytes) took fractions of a second to return,
but what surprised me most of all was:

=end original

count(*) と avg(bytes) のような問い合わせは、たちまち返ってきました。
しかし何より驚いたことは:

  SELECT url, count(*) as count FROM access_log
    GROUP BY url
    ORDER BY count desc
    LIMIT 20

=begin original

To discover the top 20 hit URLs on the site (http://axkit.org), and it
returned within 2 seconds. I'm seriously considering switching my log
analysis code to use this little speed demon!

=end original

サイト (http://axkit.org) にヒットし たURL のトップ 20 を見つけることでした。
これを 2 秒以内で返しました。
私は真剣に私のログ解析コードを、この小さな
スピードの魔物を使うように変更することを考えています。

=begin original

Oh yeah, and that was with no indexes on the table, on a 400MHz PIII.

=end original

そうそう、テーブルにはインデックスをつけていませんし、400MHz PIII の上です。

=begin original

For best performance be sure to tune your hdparm settings if you are
using linux. Also you might want to set:

=end original

パフォーマンスを最高にするためには、linux を使っているのであれば、
hdparam のセッティングを確実にチューンしてください。
またこのように設定したいかもしれません:

  PRAGMA default_synchronous = OFF

=begin original

Which will prevent sqlite from doing fsync's when writing, which will
slow down non-transactional writes significantly, at the expense of some
piece of mind. Also try playing with the cache_size pragma.

=end original

これは、いくらかの心配を犠牲にすることで、トランザクションを使わない
書込みを非常に遅くしてしまう fsync がすることから、sqlite を保護します。
cache_size pragma でも楽しんでみるようにしてください。

=head1 BUGS

=begin original

Likely to be many, please use http://rt.cpan.org/ for reporting bugs.

=end original

多くのものと同じように、バグの報告のためには http://rt.cpan.org/ を
使ってください。

=head1 AUTHOR

Matt Sergeant, matt@sergeant.org

=head1 SEE ALSO

L<DBI>.

